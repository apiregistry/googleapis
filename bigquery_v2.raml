#%RAML 1.0
title: BigQuery API
version: v2
baseUri: https://www.googleapis.com/bigquery/v2/
uses:
  commons: https://raw.githubusercontent.com/apiregistry/commons/master/commons.raml
(commons.Links):
- title: Developer Documentation
  url: https://cloud.google.com/bigquery/
  role: documentation
(commons.Icons):
- url: https://www.google.com/images/icons/product/search-32.gif
  name: x32
- url: https://www.google.com/images/icons/product/search-16.gif
  name: x16
(commons.Id): bigquery:v2
securitySchemes:
  oath2:
    type: OAuth 2.0
    description: Google Oath2.0 authorization. Detailed documentation can be found at https://developers.google.com/identity/protocols/OAuth2
    settings:
      authorizationGrants:
      - authorization_code
      - implicit
      authorizationUri: https://accounts.google.com/o/oauth2/v2/auth
      accessTokenUri: https://accounts.google.com/o/oauth2/v2/auth
      scopes:
      - https://www.googleapis.com/auth/bigquery
      - https://www.googleapis.com/auth/bigquery.insertdata
      - https://www.googleapis.com/auth/devstorage.read_only
      - https://www.googleapis.com/auth/cloud-platform.read-only
      - https://www.googleapis.com/auth/devstorage.full_control
      - https://www.googleapis.com/auth/cloud-platform
      - https://www.googleapis.com/auth/devstorage.read_write
traits:
  hasParameters:
    queryParameters:
      quotaUser?:
        type: string
        description: Available to use for quota purposes for server-side applications. Can be any arbitrary string assigned to a user, but should not exceed 40 characters. Overrides userIp if both are provided.
      prettyPrint?:
        type: boolean
        default: true
        description: Returns response with indentations and line breaks.
      userIp?:
        type: string
        description: IP address of the site where the request originates. Use this if you want to enforce per-user limits.
      fields?:
        type: string
        description: Selector specifying which fields to include in a partial response.
securedBy:
  oath2: 
types:
  JsonValue:
    type: any
  BigtableColumn:
    type: object
    properties:
      qualifierEncoded?:
        type: string
        description: '[Required] Qualifier of the column. Columns in the parent column
          family that has this exact qualifier are exposed as . field. If the qualifier
          is valid UTF-8 string, it can be specified in the qualifier_string field.
          Otherwise, a base-64 encoded value must be set to qualifier_encoded. The
          column field name is the same as the column qualifier. However, if the qualifier
          is not a valid BigQuery field identifier i.e. does not match [a-zA-Z][a-zA-Z0-9_]*,
          a valid identifier must be provided as field_name.'
      fieldName?:
        type: string
        description: '[Optional] If the qualifier is not a valid BigQuery field identifier
          i.e. does not match [a-zA-Z][a-zA-Z0-9_]*, a valid identifier must be provided
          as the column field name and is used as field name in queries.'
      encoding?:
        type: string
        description: '[Optional] The encoding of the values when the type is not STRING.
          Acceptable encoding values are: TEXT - indicates values are alphanumeric
          text strings. BINARY - indicates values are encoded using HBase Bytes.toBytes
          family of functions. ''encoding'' can also be set at the column family level.
          However, the setting at this level takes precedence if ''encoding'' is set
          at both levels.'
      qualifierString?:
        type: string
      type?:
        type: string
        description: '[Optional] The type to convert the value in cells of this column.
          The values are expected to be encoded using HBase Bytes.toBytes function
          when using the BINARY encoding value. Following BigQuery types are allowed
          (case-sensitive) - BYTES STRING INTEGER FLOAT BOOLEAN Default type is BYTES.
          ''type'' can also be set at the column family level. However, the setting
          at this level takes precedence if ''type'' is set at both levels.'
      onlyReadLatest?:
        type: boolean
        description: '[Optional] If this is set, only the latest version of value
          in this column are exposed. ''onlyReadLatest'' can also be set at the column
          family level. However, the setting at this level takes precedence if ''onlyReadLatest''
          is set at both levels.'
  BigtableColumnFamily:
    type: object
    properties:
      familyId?:
        type: string
        description: Identifier of the column family.
      columns?:
        type: array
        description: '[Optional] Lists of columns that should be exposed as individual
          fields as opposed to a list of (column name, value) pairs. All columns whose
          qualifier matches a qualifier in this list can be accessed as .. Other columns
          can be accessed as a list through .Column field.'
        items: BigtableColumn
      encoding?:
        type: string
        description: '[Optional] The encoding of the values when the type is not STRING.
          Acceptable encoding values are: TEXT - indicates values are alphanumeric
          text strings. BINARY - indicates values are encoded using HBase Bytes.toBytes
          family of functions. This can be overridden for a specific column by listing
          that column in ''columns'' and specifying an encoding for it.'
      type?:
        type: string
        description: '[Optional] The type to convert the value in cells of this column
          family. The values are expected to be encoded using HBase Bytes.toBytes
          function when using the BINARY encoding value. Following BigQuery types
          are allowed (case-sensitive) - BYTES STRING INTEGER FLOAT BOOLEAN Default
          type is BYTES. This can be overridden for a specific column by listing that
          column in ''columns'' and specifying a type for it.'
      onlyReadLatest?:
        type: boolean
        description: '[Optional] If this is set only the latest version of value are
          exposed for all columns in this column family. This can be overridden for
          a specific column by listing that column in ''columns'' and specifying a
          different setting for that column.'
  BigtableOptions:
    type: object
    properties:
      columnFamilies?:
        type: array
        description: '[Optional] List of column families to expose in the table schema
          along with their types. This list restricts the column families that can
          be referenced in queries and specifies their value types. You can use this
          list to do type conversions - see the ''type'' field for more details. If
          you leave this list empty, all column families are present in the table
          schema and their values are read as BYTES. During a query only the column
          families referenced in that query are read from Bigtable.'
        items: BigtableColumnFamily
      ignoreUnspecifiedColumnFamilies?:
        type: boolean
        description: '[Optional] If field is true, then the column families that are
          not specified in columnFamilies list are not exposed in the table schema.
          Otherwise, they are read with BYTES type values. The default value is false.'
      readRowkeyAsString?:
        type: boolean
        description: '[Optional] If field is true, then the rowkey column families
          will be read and converted to string. Otherwise they are read with BYTES
          type values and users need to manually cast them with CAST if necessary.
          The default value is false.'
  CsvOptions:
    type: object
    properties:
      allowQuotedNewlines?:
        type: boolean
        description: '[Optional] Indicates if BigQuery should allow quoted data sections
          that contain newline characters in a CSV file. The default value is false.'
      skipLeadingRows?:
        type: integer
        format: int64
        description: '[Optional] The number of rows at the top of a CSV file that
          BigQuery will skip when reading the data. The default value is 0. This property
          is useful if you have header rows in the file that should be skipped.'
      quote?:
        type: string
        default: '"'
        pattern: .?
        description: '[Optional] The value that is used to quote data sections in
          a CSV file. BigQuery converts the string to ISO-8859-1 encoding, and then
          uses the first byte of the encoded string to split the data in its raw,
          binary state. The default value is a double-quote (''"''). If your data
          does not contain quoted sections, set the property value to an empty string.
          If your data contains quoted newline characters, you must also set the allowQuotedNewlines
          property to true.'
      encoding?:
        type: string
        description: '[Optional] The character encoding of the data. The supported
          values are UTF-8 or ISO-8859-1. The default value is UTF-8. BigQuery decodes
          the data after the raw, binary data has been split using the values of the
          quote and fieldDelimiter properties.'
      fieldDelimiter?:
        type: string
        description: '[Optional] The separator for fields in a CSV file. BigQuery
          converts the string to ISO-8859-1 encoding, and then uses the first byte
          of the encoded string to split the data in its raw, binary state. BigQuery
          also supports the escape sequence "\t" to specify a tab separator. The default
          value is a comma ('','').'
      allowJaggedRows?:
        type: boolean
        description: '[Optional] Indicates if BigQuery should accept rows that are
          missing trailing optional columns. If true, BigQuery treats missing trailing
          columns as null values. If false, records with missing trailing columns
          are treated as bad records, and if there are too many bad records, an invalid
          error is returned in the job result. The default value is false.'
  Dataset:
    type: object
    properties:
      access?:
        type: array
        description: '[Optional] An array of objects that define dataset access for
          one or more entities. You can set this property when inserting or updating
          a dataset in order to control who is allowed to access the data. If unspecified
          at dataset creation time, BigQuery adds default dataset access for the following
          entities: access.specialGroup: projectReaders; access.role: READER; access.specialGroup:
          projectWriters; access.role: WRITER; access.specialGroup: projectOwners;
          access.role: OWNER; access.userByEmail: [dataset creator email]; access.role:
          OWNER;'
        items:
          type: object
          properties:
            view?: TableReference
            role?:
              type: string
              description: '[Required] Describes the rights granted to the user specified
                by the other member of the access object. The following string values
                are supported: READER, WRITER, OWNER.'
            userByEmail?:
              type: string
              description: '[Pick one] An email address of a user to grant access
                to. For example: fred@example.com.'
            domain?:
              type: string
              description: '[Pick one] A domain to grant access to. Any users signed
                in with the domain specified will be granted the specified access.
                Example: "example.com".'
            specialGroup?:
              type: string
              description: '[Pick one] A special group to grant access to. Possible
                values include: projectOwners: Owners of the enclosing project. projectReaders:
                Readers of the enclosing project. projectWriters: Writers of the enclosing
                project. allAuthenticatedUsers: All authenticated BigQuery users.'
            groupByEmail?:
              type: string
              description: '[Pick one] An email address of a Google Group to grant
                access to.'
      lastModifiedTime?:
        type: integer
        format: int64
        description: '[Output-only] The date when this dataset or any of its tables
          was last modified, in milliseconds since the epoch.'
      creationTime?:
        type: integer
        format: int64
        description: '[Output-only] The time when this dataset was created, in milliseconds
          since the epoch.'
      kind?:
        type: string
        default: bigquery#dataset
        description: '[Output-only] The resource type.'
      description?:
        type: string
        description: '[Optional] A user-friendly description of the dataset.'
      datasetReference?: DatasetReference
      labels?:
        type: object
        description: '[Experimental] The labels associated with this dataset. You
          can use these to organize and group your datasets. You can set this property
          when inserting or updating a dataset. See Labeling Datasets for more information.'
      selfLink?:
        type: string
        description: '[Output-only] A URL that can be used to access the resource
          again. You can use this URL in Get or Update requests to the resource.'
      etag?:
        type: string
        description: '[Output-only] A hash of the resource.'
      location?:
        type: string
        description: '[Experimental] The geographic location where the dataset should
          reside. Possible values include EU and US. The default value is US.'
      defaultTableExpirationMs?:
        type: integer
        format: int64
        description: '[Optional] The default lifetime of all tables in the dataset,
          in milliseconds. The minimum value is 3600000 milliseconds (one hour). Once
          this property is set, all newly-created tables in the dataset will have
          an expirationTime property set to the creation time plus the value in this
          property, and changing the value will only affect new tables, not existing
          ones. When the expirationTime for a given table is reached, that table will
          be deleted automatically. If a table''s expirationTime is modified or removed
          before the table expires, or if you provide an explicit expirationTime when
          creating a table, that value takes precedence over the default expiration
          time indicated by this property.'
      id?:
        type: string
        description: '[Output-only] The fully-qualified unique name of the dataset
          in the format projectId:datasetId. The dataset name without the project
          name is given in the datasetId field. When creating a new dataset, leave
          this field blank, and instead specify the datasetId field.'
      friendlyName?:
        type: string
        description: '[Optional] A descriptive name for the dataset.'
  DatasetList:
    type: object
    properties:
      kind?:
        type: string
        default: bigquery#datasetList
        description: The list type. This property always returns the value "bigquery#datasetList".
      nextPageToken?:
        type: string
        description: A token that can be used to request the next results page. This property is omitted on the final results page.
      etag?:
        type: string
        description: A hash value of the results page. You can use this property to determine if the page has changed since the last request.
      datasets?:
        type: array
        description: 'An array of the dataset resources in the project. Each resource
          contains basic information. For full information about a particular dataset
          resource, use the Datasets: get method. This property is omitted when there
          are no datasets in the project.'
        items:
          type: object
          properties:
            kind?:
              type: string
              default: bigquery#dataset
              description: The resource type. This property always returns the value "bigquery#dataset".
            id?:
              type: string
              description: The fully-qualified, unique, opaque ID of the dataset.
            datasetReference?: DatasetReference
            friendlyName?:
              type: string
              description: A descriptive name for the dataset, if one exists.
            labels?:
              type: object
              description: '[Experimental] The labels associated with this dataset.
                You can use these to organize and group your datasets.'
  DatasetReference:
    type: object
    properties:
      datasetId?:
        type: string
        description: '[Required] A unique ID for this dataset, without the project
          name. The ID must contain only letters (a-z, A-Z), numbers (0-9), or underscores
          (_). The maximum length is 1,024 characters.'
      projectId?:
        type: string
        description: '[Optional] The ID of the project containing this dataset.'
  ErrorProto:
    type: object
    properties:
      reason?:
        type: string
        description: A short error code that summarizes the error.
      location?:
        type: string
        description: Specifies where the error occurred, if present.
      debugInfo?:
        type: string
        description: Debugging information. This property is internal to Google and should not be used.
      message?:
        type: string
        description: A human-readable description of the error.
  ExplainQueryStage:
    type: object
    properties:
      readRatioMax?:
        type: number
        format: double
        description: Relative amount of time the slowest shard spent reading input.
      computeRatioAvg?:
        type: number
        format: double
        description: Relative amount of time the average shard spent on CPU-bound tasks.
      writeRatioAvg?:
        type: number
        format: double
        description: Relative amount of time the average shard spent on writing output.
      recordsRead?:
        type: integer
        format: int64
        description: Number of records read into the stage.
      waitRatioMax?:
        type: number
        format: double
        description: Relative amount of time the slowest shard spent waiting to be scheduled.
      computeRatioMax?:
        type: number
        format: double
        description: Relative amount of time the slowest shard spent on CPU-bound tasks.
      steps?:
        type: array
        description: List of operations within the stage in dependency order (approximately chronological).
        items: ExplainQueryStep
      readRatioAvg?:
        type: number
        format: double
        description: Relative amount of time the average shard spent reading input.
      name?:
        type: string
        description: Human-readable name for stage.
      recordsWritten?:
        type: integer
        format: int64
        description: Number of records written by the stage.
      writeRatioMax?:
        type: number
        format: double
        description: Relative amount of time the slowest shard spent on writing output.
      id?:
        type: integer
        format: int64
        description: Unique ID for stage within plan.
      waitRatioAvg?:
        type: number
        format: double
        description: Relative amount of time the average shard spent waiting to be scheduled.
  ExplainQueryStep:
    type: object
    properties:
      substeps?:
        type: array
        description: Human-readable stage descriptions.
        items:
          type: string
      kind?:
        type: string
        description: Machine-readable operation type.
  ExternalDataConfiguration:
    type: object
    properties:
      schema?: TableSchema
      autodetect?:
        type: boolean
        description: '[Experimental] Try to detect schema and format options automatically.
          Any option specified explicitly will be honored.'
      sourceUris?:
        type: array
        description: '[Required] The fully-qualified URIs that point to your data
          in Google Cloud. For Google Cloud Storage URIs: Each URI can contain one
          ''*'' wildcard character and it must come after the ''bucket'' name. Size
          limits related to load jobs apply to external data sources. For Google Cloud
          Bigtable URIs: Exactly one URI can be specified and it has be a fully specified
          and valid HTTPS URL for a Google Cloud Bigtable table. For Google Cloud
          Datastore backups, exactly one URI can be specified, and it must end with
          ''.backup_info''. Also, the ''*'' wildcard character is not allowed.'
        items:
          type: string
      bigtableOptions?: BigtableOptions
      csvOptions?: CsvOptions
      ignoreUnknownValues?:
        type: boolean
        description: '[Optional] Indicates if BigQuery should allow extra values that
          are not represented in the table schema. If true, the extra values are ignored.
          If false, records with extra columns are treated as bad records, and if
          there are too many bad records, an invalid error is returned in the job
          result. The default value is false. The sourceFormat property determines
          what BigQuery treats as an extra value: CSV: Trailing columns JSON: Named
          values that don''t match any column names Google Cloud Bigtable: This setting
          is ignored. Google Cloud Datastore backups: This setting is ignored. Avro:
          This setting is ignored.'
      googleSheetsOptions?: GoogleSheetsOptions
      compression?:
        type: string
        description: '[Optional] The compression type of the data source. Possible
          values include GZIP and NONE. The default value is NONE. This setting is
          ignored for Google Cloud Bigtable, Google Cloud Datastore backups and Avro
          formats.'
      sourceFormat?:
        type: string
        description: '[Required] The data format. For CSV files, specify "CSV". For
          Google sheets, specify "GOOGLE_SHEETS". For newline-delimited JSON, specify
          "NEWLINE_DELIMITED_JSON". For Avro files, specify "AVRO". For Google Cloud
          Datastore backups, specify "DATASTORE_BACKUP". [Experimental] For Google
          Cloud Bigtable, specify "BIGTABLE". Please note that reading from Google
          Cloud Bigtable is experimental and has to be enabled for your project. Please
          contact Google Cloud Support to enable this for your project.'
      maxBadRecords?:
        type: integer
        format: int32
        description: '[Optional] The maximum number of bad records that BigQuery can
          ignore when reading data. If the number of bad records exceeds this value,
          an invalid error is returned in the job result. The default value is 0,
          which requires that all records are valid. This setting is ignored for Google
          Cloud Bigtable, Google Cloud Datastore backups and Avro formats.'
  GetQueryResultsResponse:
    type: object
    properties:
      schema?: TableSchema
      kind?:
        type: string
        default: bigquery#getQueryResultsResponse
        description: The resource type of the response.
      cacheHit?:
        type: boolean
        description: Whether the query result was fetched from the query cache.
      etag?:
        type: string
        description: A hash of this response.
      jobComplete?:
        type: boolean
        description: Whether the query has completed or not. If rows or totalRows are present, this will always be true. If this is false, totalRows will not be available.
      numDmlAffectedRows?:
        type: integer
        format: int64
        description: '[Output-only, Experimental] The number of rows affected by a
          DML statement. Present only for DML statements INSERT, UPDATE or DELETE.'
      pageToken?:
        type: string
        description: A token used for paging results.
      totalRows?:
        type: integer
        format: int64
        description: The total number of rows in the complete query result set, which can be more than the number of rows in this single page of results. Present only when the query completes successfully.
      jobReference?: JobReference
      rows?:
        type: array
        description: An object with as many results as can be contained within the maximum permitted reply size. To get any additional rows, you can call GetQueryResults and specify the jobReference returned above. Present only when the query completes successfully.
        items: TableRow
      errors?:
        type: array
        description: '[Output-only] All errors and warnings encountered during the
          running of the job. Errors here do not necessarily mean that the job has
          completed or was unsuccessful.'
        items: ErrorProto
      totalBytesProcessed?:
        type: integer
        format: int64
        description: The total number of bytes processed for this query.
  GoogleSheetsOptions:
    type: object
    properties:
      skipLeadingRows?:
        type: integer
        format: int64
        description: '[Optional] The number of rows at the top of a sheet that BigQuery
          will skip when reading the data. The default value is 0. This property is
          useful if you have header rows that should be skipped. When autodetect is
          on, behavior is the following: * skipLeadingRows unspecified - Autodetect
          tries to detect headers in the first row. If they are not detected, the
          row is read as data. Otherwise data is read starting from the second row.
          * skipLeadingRows is 0 - Instructs autodetect that there are no headers
          and data should be read starting from the first row. * skipLeadingRows =
          N > 0 - Autodetect skips N-1 rows and tries to detect headers in row N.
          If headers are not detected, row N is just skipped. Otherwise row N is used
          to extract column names for the detected schema.'
  Job:
    type: object
    properties:
      user_email?:
        type: string
        description: '[Output-only] Email address of the user who ran the job.'
      configuration?: JobConfiguration
      kind?:
        type: string
        default: bigquery#job
        description: '[Output-only] The type of the resource.'
      etag?:
        type: string
        description: '[Output-only] A hash of this resource.'
      id?:
        type: string
        description: '[Output-only] Opaque ID field of the job'
      jobReference?: JobReference
      selfLink?:
        type: string
        description: '[Output-only] A URL that can be used to access this resource
          again.'
      statistics?: JobStatistics
      status?: JobStatus
  JobCancelResponse:
    type: object
    properties:
      kind?:
        type: string
        default: bigquery#jobCancelResponse
        description: The resource type of the response.
      job?: Job
  JobConfiguration:
    type: object
    properties:
      dryRun?:
        type: boolean
        description: '[Optional] If set, don''t actually run this job. A valid query
          will return a mostly empty response with some processing statistics, while
          an invalid query will return the same error it would if it wasn''t a dry
          run. Behavior of non-query jobs is undefined.'
      extract?: JobConfigurationExtract
      load?: JobConfigurationLoad
      query?: JobConfigurationQuery
      copy?: JobConfigurationTableCopy
      labels?:
        type: object
        description: '[Experimental] The labels associated with this job. You can
          use these to organize and group your jobs. Label keys and values can be
          no longer than 63 characters, can only contain letters, numeric characters,
          underscores and dashes. International characters are allowed. Label values
          are optional. Label keys must start with a letter and must be unique within
          a dataset. Both keys and values are additionally constrained to be <= 128
          bytes in size.'
  JobConfigurationExtract:
    type: object
    properties:
      sourceTable?: TableReference
      destinationUri?:
        type: string
        description: '[Pick one] DEPRECATED: Use destinationUris instead, passing
          only one URI as necessary. The fully-qualified Google Cloud Storage URI
          where the extracted table should be written.'
      destinationUris?:
        type: array
        description: '[Pick one] A list of fully-qualified Google Cloud Storage URIs
          where the extracted table should be written.'
        items:
          type: string
      printHeader?:
        type: boolean
        default: true
        description: '[Optional] Whether to print out a header row in the results.
          Default is true.'
      destinationFormat?:
        type: string
        description: '[Optional] The exported file format. Possible values include
          CSV, NEWLINE_DELIMITED_JSON and AVRO. The default value is CSV. Tables with
          nested or repeated fields cannot be exported as CSV.'
      compression?:
        type: string
        description: '[Optional] The compression type to use for exported files. Possible
          values include GZIP and NONE. The default value is NONE.'
      fieldDelimiter?:
        type: string
        description: '[Optional] Delimiter to use between fields in the exported data.
          Default is '','''
  JobConfigurationLoad:
    type: object
    properties:
      schema?: TableSchema
      schemaUpdateOptions?:
        type: array
        description: '[Experimental] Allows the schema of the desitination table to
          be updated as a side effect of the load job. Schema update options are supported
          in two cases: when writeDisposition is WRITE_APPEND; when writeDisposition
          is WRITE_TRUNCATE and the destination table is a partition of a table, specified
          by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite
          the schema. One or more of the following values are specified: ALLOW_FIELD_ADDITION:
          allow adding a nullable field to the schema. ALLOW_FIELD_RELAXATION: allow
          relaxing a required field in the original schema to nullable.'
        items:
          type: string
      allowQuotedNewlines?:
        type: boolean
        description: Indicates if BigQuery should allow quoted data sections that contain newline characters in a CSV file. The default value is false.
      projectionFields?:
        type: array
        description: '[Experimental] If sourceFormat is set to "DATASTORE_BACKUP",
          indicates which entity properties to load into BigQuery from a Cloud Datastore
          backup. Property names are case sensitive and must be top-level properties.
          If no properties are specified, BigQuery loads all properties. If any named
          property isn''t found in the Cloud Datastore backup, an invalid error is
          returned in the job result.'
        items:
          type: string
      sourceUris?:
        type: array
        description: '[Required] The fully-qualified URIs that point to your data
          in Google Cloud Storage. Each URI can contain one ''*'' wildcard character
          and it must come after the ''bucket'' name.'
        items:
          type: string
      schemaInlineFormat?:
        type: string
        description: '[Deprecated] The format of the schemaInline property.'
      writeDisposition?:
        type: string
        description: '[Optional] Specifies the action that occurs if the destination
          table already exists. The following values are supported: WRITE_TRUNCATE:
          If the table already exists, BigQuery overwrites the table data. WRITE_APPEND:
          If the table already exists, BigQuery appends the data to the table. WRITE_EMPTY:
          If the table already exists and contains data, a ''duplicate'' error is
          returned in the job result. The default value is WRITE_APPEND. Each action
          is atomic and only occurs if BigQuery is able to complete the job successfully.
          Creation, truncation and append actions occur as one atomic update upon
          job completion.'
      ignoreUnknownValues?:
        type: boolean
        description: '[Optional] Indicates if BigQuery should allow extra values that
          are not represented in the table schema. If true, the extra values are ignored.
          If false, records with extra columns are treated as bad records, and if
          there are too many bad records, an invalid error is returned in the job
          result. The default value is false. The sourceFormat property determines
          what BigQuery treats as an extra value: CSV: Trailing columns JSON: Named
          values that don''t match any column names'
      encoding?:
        type: string
        description: '[Optional] The character encoding of the data. The supported
          values are UTF-8 or ISO-8859-1. The default value is UTF-8. BigQuery decodes
          the data after the raw, binary data has been split using the values of the
          quote and fieldDelimiter properties.'
      fieldDelimiter?:
        type: string
        description: '[Optional] The separator for fields in a CSV file. The separator
          can be any ISO-8859-1 single-byte character. To use a character in the range
          128-255, you must encode the character as UTF8. BigQuery converts the string
          to ISO-8859-1 encoding, and then uses the first byte of the encoded string
          to split the data in its raw, binary state. BigQuery also supports the escape
          sequence "\t" to specify a tab separator. The default value is a comma ('','').'
      allowJaggedRows?:
        type: boolean
        description: '[Optional] Accept rows that are missing trailing optional columns.
          The missing values are treated as nulls. If false, records with missing
          trailing columns are treated as bad records, and if there are too many bad
          records, an invalid error is returned in the job result. The default value
          is false. Only applicable to CSV, ignored for other formats.'
      autodetect?:
        type: boolean
        description: '[Experimental] Indicates if we should automatically infer the
          options and schema for CSV and JSON sources.'
      skipLeadingRows?:
        type: integer
        format: int32
        description: '[Optional] The number of rows at the top of a CSV file that
          BigQuery will skip when loading the data. The default value is 0. This property
          is useful if you have header rows in the file that should be skipped.'
      quote?:
        type: string
        default: '"'
        pattern: .?
        description: '[Optional] The value that is used to quote data sections in
          a CSV file. BigQuery converts the string to ISO-8859-1 encoding, and then
          uses the first byte of the encoded string to split the data in its raw,
          binary state. The default value is a double-quote (''"''). If your data
          does not contain quoted sections, set the property value to an empty string.
          If your data contains quoted newline characters, you must also set the allowQuotedNewlines
          property to true.'
      destinationTable?: TableReference
      schemaInline?:
        type: string
        description: '[Deprecated] The inline schema. For CSV schemas, specify as
          "Field1:Type1[,Field2:Type2]*". For example, "foo:STRING, bar:INTEGER, baz:FLOAT".'
      sourceFormat?:
        type: string
        description: '[Optional] The format of the data files. For CSV files, specify
          "CSV". For datastore backups, specify "DATASTORE_BACKUP". For newline-delimited
          JSON, specify "NEWLINE_DELIMITED_JSON". For Avro, specify "AVRO". The default
          value is CSV.'
      maxBadRecords?:
        type: integer
        format: int32
        description: '[Optional] The maximum number of bad records that BigQuery can
          ignore when running the job. If the number of bad records exceeds this value,
          an invalid error is returned in the job result. The default value is 0,
          which requires that all records are valid.'
      createDisposition?:
        type: string
        description: '[Optional] Specifies whether the job is allowed to create new
          tables. The following values are supported: CREATE_IF_NEEDED: If the table
          does not exist, BigQuery creates the table. CREATE_NEVER: The table must
          already exist. If it does not, a ''notFound'' error is returned in the job
          result. The default value is CREATE_IF_NEEDED. Creation, truncation and
          append actions occur as one atomic update upon job completion.'
  JobConfigurationQuery:
    type: object
    properties:
      schemaUpdateOptions?:
        type: array
        description: '[Experimental] Allows the schema of the destination table to
          be updated as a side effect of the query job. Schema update options are
          supported in two cases: when writeDisposition is WRITE_APPEND; when writeDisposition
          is WRITE_TRUNCATE and the destination table is a partition of a table, specified
          by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite
          the schema. One or more of the following values are specified: ALLOW_FIELD_ADDITION:
          allow adding a nullable field to the schema. ALLOW_FIELD_RELAXATION: allow
          relaxing a required field in the original schema to nullable.'
        items:
          type: string
      userDefinedFunctionResources?:
        type: array
        description: '[Experimental] Describes user-defined function resources used
          in the query.'
        items: UserDefinedFunctionResource
      allowLargeResults?:
        type: boolean
        description: If true, allows the query to produce arbitrarily large result tables at a slight cost in performance. Requires destinationTable to be set.
      useQueryCache?:
        type: boolean
        default: true
        description: '[Optional] Whether to look for the result in the query cache.
          The query cache is a best-effort cache that will be flushed whenever tables
          in the query are modified. Moreover, the query cache is only available when
          a query does not have a destination table specified. The default value is
          true.'
      preserveNulls?:
        type: boolean
        description: '[Deprecated] This property is deprecated.'
      query?:
        type: string
        description: '[Required] BigQuery SQL query to execute.'
      writeDisposition?:
        type: string
        description: '[Optional] Specifies the action that occurs if the destination
          table already exists. The following values are supported: WRITE_TRUNCATE:
          If the table already exists, BigQuery overwrites the table data. WRITE_APPEND:
          If the table already exists, BigQuery appends the data to the table. WRITE_EMPTY:
          If the table already exists and contains data, a ''duplicate'' error is
          returned in the job result. The default value is WRITE_EMPTY. Each action
          is atomic and only occurs if BigQuery is able to complete the job successfully.
          Creation, truncation and append actions occur as one atomic update upon
          job completion.'
      maximumBytesBilled?:
        type: integer
        format: int64
        description: '[Optional] Limits the bytes billed for this job. Queries that
          will have bytes billed beyond this limit will fail (without incurring a
          charge). If unspecified, this will be set to your project default.'
      maximumBillingTier?:
        type: integer
        default: 1
        format: int32
        description: '[Optional] Limits the billing tier for this job. Queries that
          have resource usage beyond this tier will fail (without incurring a charge).
          If unspecified, this will be set to your project default.'
      priority?:
        type: string
        description: '[Optional] Specifies a priority for the query. Possible values
          include INTERACTIVE and BATCH. The default value is INTERACTIVE.'
      defaultDataset?: DatasetReference
      flattenResults?:
        type: boolean
        default: true
        description: '[Optional] Flattens all nested and repeated fields in the query
          results. The default value is true. allowLargeResults must be true if this
          is set to false.'
      parameterMode?:
        type: string
        description: '[Experimental] Standard SQL only. Whether to use positional
          (?) or named (@myparam) query parameters in this query.'
      queryParameters?:
        type: array
        description: Query parameters for standard SQL queries.
        items: QueryParameter
      destinationTable?: TableReference
      tableDefinitions?:
        type: object
        description: '[Optional] If querying an external data source outside of BigQuery,
          describes the data format, location and other properties of the data source.
          By defining these properties, the data source can then be queried as if
          it were a standard BigQuery table.'
      createDisposition?:
        type: string
        description: '[Optional] Specifies whether the job is allowed to create new
          tables. The following values are supported: CREATE_IF_NEEDED: If the table
          does not exist, BigQuery creates the table. CREATE_NEVER: The table must
          already exist. If it does not, a ''notFound'' error is returned in the job
          result. The default value is CREATE_IF_NEEDED. Creation, truncation and
          append actions occur as one atomic update upon job completion.'
      useLegacySql?:
        type: boolean
        description: '[Experimental] Specifies whether to use BigQuery''s legacy SQL
          dialect for this query. The default value is true. If set to false, the
          query will use BigQuery''s standard SQL: https://cloud.google.com/bigquery/sql-reference/
          When useLegacySql is set to false, the values of allowLargeResults and flattenResults
          are ignored; query will be run as if allowLargeResults is true and flattenResults
          is false.'
  JobConfigurationTableCopy:
    type: object
    properties:
      sourceTable?: TableReference
      destinationTable?: TableReference
      sourceTables?:
        type: array
        description: '[Pick one] Source tables to copy.'
        items: TableReference
      writeDisposition?:
        type: string
        description: '[Optional] Specifies the action that occurs if the destination
          table already exists. The following values are supported: WRITE_TRUNCATE:
          If the table already exists, BigQuery overwrites the table data. WRITE_APPEND:
          If the table already exists, BigQuery appends the data to the table. WRITE_EMPTY:
          If the table already exists and contains data, a ''duplicate'' error is
          returned in the job result. The default value is WRITE_EMPTY. Each action
          is atomic and only occurs if BigQuery is able to complete the job successfully.
          Creation, truncation and append actions occur as one atomic update upon
          job completion.'
      createDisposition?:
        type: string
        description: '[Optional] Specifies whether the job is allowed to create new
          tables. The following values are supported: CREATE_IF_NEEDED: If the table
          does not exist, BigQuery creates the table. CREATE_NEVER: The table must
          already exist. If it does not, a ''notFound'' error is returned in the job
          result. The default value is CREATE_IF_NEEDED. Creation, truncation and
          append actions occur as one atomic update upon job completion.'
  JobList:
    type: object
    properties:
      kind?:
        type: string
        default: bigquery#jobList
        description: The resource type of the response.
      nextPageToken?:
        type: string
        description: A token to request the next page of results.
      jobs?:
        type: array
        description: List of jobs that were requested.
        items:
          type: object
          properties:
            user_email?:
              type: string
              description: '[Full-projection-only] Email address of the user who ran
                the job.'
            configuration?: JobConfiguration
            errorResult?: ErrorProto
            kind?:
              type: string
              default: bigquery#job
              description: The resource type.
            id?:
              type: string
              description: Unique opaque ID of the job.
            state?:
              type: string
              description: Running state of the job. When the state is DONE, errorResult can be checked to determine whether the job succeeded or failed.
            jobReference?: JobReference
            statistics?: JobStatistics
            status?: JobStatus
      etag?:
        type: string
        description: A hash of this page of results.
  JobReference:
    type: object
    properties:
      jobId?:
        type: string
        description: '[Required] The ID of the job. The ID must contain only letters
          (a-z, A-Z), numbers (0-9), underscores (_), or dashes (-). The maximum length
          is 1,024 characters.'
      projectId?:
        type: string
        description: '[Required] The ID of the project containing this job.'
  JobStatistics:
    type: object
    properties:
      extract?: JobStatistics4
      creationTime?:
        type: integer
        format: int64
        description: '[Output-only] Creation time of this job, in milliseconds since
          the epoch. This field will be present on all jobs.'
      load?: JobStatistics3
      query?: JobStatistics2
      startTime?:
        type: integer
        format: int64
        description: '[Output-only] Start time of this job, in milliseconds since
          the epoch. This field will be present when the job transitions from the
          PENDING state to either RUNNING or DONE.'
      endTime?:
        type: integer
        format: int64
        description: '[Output-only] End time of this job, in milliseconds since the
          epoch. This field will be present whenever a job is in the DONE state.'
      totalBytesProcessed?:
        type: integer
        format: int64
        description: '[Output-only] [Deprecated] Use the bytes processed in the query
          statistics instead.'
  JobStatistics2:
    type: object
    properties:
      schema?: TableSchema
      totalBytesBilled?:
        type: integer
        format: int64
        description: '[Output-only] Total bytes billed for the job.'
      undeclaredQueryParameters?:
        type: array
        description: '[Output-only, Experimental] Standard SQL only: list of undeclared
          query parameters detected during a dry run validation.'
        items: QueryParameter
      cacheHit?:
        type: boolean
        description: '[Output-only] Whether the query result was fetched from the
          query cache.'
      numDmlAffectedRows?:
        type: integer
        format: int64
        description: '[Output-only, Experimental] The number of rows affected by a
          DML statement. Present only for DML statements INSERT, UPDATE or DELETE.'
      queryPlan?:
        type: array
        description: '[Output-only, Experimental] Describes execution plan for the
          query.'
        items: ExplainQueryStage
      billingTier?:
        type: integer
        format: int32
        description: '[Output-only] Billing tier for the job.'
      referencedTables?:
        type: array
        description: '[Output-only, Experimental] Referenced tables for the job. Queries
          that reference more than 50 tables will not have a complete list.'
        items: TableReference
      totalBytesProcessed?:
        type: integer
        format: int64
        description: '[Output-only] Total bytes processed for the job.'
  JobStatistics3:
    type: object
    properties:
      inputFileBytes?:
        type: integer
        format: int64
        description: '[Output-only] Number of bytes of source data in a load job.'
      outputRows?:
        type: integer
        format: int64
        description: '[Output-only] Number of rows imported in a load job. Note that
          while an import job is in the running state, this value may change.'
      inputFiles?:
        type: integer
        format: int64
        description: '[Output-only] Number of source files in a load job.'
      outputBytes?:
        type: integer
        format: int64
        description: '[Output-only] Size of the loaded data in bytes. Note that while
          a load job is in the running state, this value may change.'
  JobStatistics4:
    type: object
    properties:
      destinationUriFileCounts?:
        type: array
        description: '[Output-only] Number of files per destination URI or URI pattern
          specified in the extract configuration. These values will be in the same
          order as the URIs specified in the ''destinationUris'' field.'
        items:
          type: integer
          format: int64
  JobStatus:
    type: object
    properties:
      errorResult?: ErrorProto
      state?:
        type: string
        description: '[Output-only] Running state of the job.'
      errors?:
        type: array
        description: '[Output-only] All errors encountered during the running of the
          job. Errors here do not necessarily mean that the job has completed or was
          unsuccessful.'
        items: ErrorProto
  JsonObject:
    type: object
    description: Represents a single JSON object.
  ProjectList:
    type: object
    properties:
      totalItems?:
        type: integer
        format: int32
        description: The total number of projects in the list.
      projects?:
        type: array
        description: Projects to which you have at least READ access.
        items:
          type: object
          properties:
            numericId?:
              type: integer
              format: int64
              description: The numeric ID of this project.
            kind?:
              type: string
              default: bigquery#project
              description: The resource type.
            id?:
              type: string
              description: An opaque ID of this project.
            friendlyName?:
              type: string
              description: A descriptive name for this project.
            projectReference?: ProjectReference
      kind?:
        type: string
        default: bigquery#projectList
        description: The type of list.
      nextPageToken?:
        type: string
        description: A token to request the next page of results.
      etag?:
        type: string
        description: A hash of the page of results
  ProjectReference:
    type: object
    properties:
      projectId?:
        type: string
        description: '[Required] ID of the project. Can be either the numeric ID or
          the assigned ID of the project.'
  QueryParameter:
    type: object
    properties:
      parameterType?: QueryParameterType
      name?:
        type: string
        description: '[Optional] If unset, this is a positional parameter. Otherwise,
          should be unique within a query.'
      parameterValue?: QueryParameterValue
  QueryParameterType:
    type: object
    properties:
      arrayType?: QueryParameterType
      type?:
        type: string
        description: '[Required] The top level type of this field.'
      structTypes?:
        type: array
        description: '[Optional] The types of the fields of this struct, in order,
          if this is a struct.'
        items:
          type: object
          properties:
            name?:
              type: string
              description: '[Optional] The name of this field.'
            description?:
              type: string
              description: '[Optional] Human-oriented description of the field.'
            type?: QueryParameterType
  QueryParameterValue:
    type: object
    properties:
      structValues?:
        type: object
        description: '[Optional] The struct field values, in order of the struct type''s
          declaration.'
      value?:
        type: string
        description: '[Optional] The value of this value, if a simple scalar type.'
      arrayValues?:
        type: array
        description: '[Optional] The array values, if this is an array type.'
        items: QueryParameterValue
  QueryRequest:
    type: object
    properties:
      dryRun?:
        type: boolean
        description: '[Optional] If set to true, BigQuery doesn''t run the job. Instead,
          if the query is valid, BigQuery returns statistics about the job such as
          how many bytes would be processed. If the query is invalid, an error returns.
          The default value is false.'
      parameterMode?:
        type: string
        description: '[Experimental] Standard SQL only. Whether to use positional
          (?) or named (@myparam) query parameters in this query.'
      useQueryCache?:
        type: boolean
        default: true
        description: '[Optional] Whether to look for the result in the query cache.
          The query cache is a best-effort cache that will be flushed whenever tables
          in the query are modified. The default value is true.'
      queryParameters?:
        type: array
        description: '[Experimental] Query parameters for Standard SQL queries.'
        items: QueryParameter
      kind?:
        type: string
        default: bigquery#queryRequest
        description: The resource type of the request.
      maxResults?:
        type: integer
        format: int32
        description: '[Optional] The maximum number of rows of data to return per
          page of results. Setting this flag to a small value such as 1000 and then
          paging through results might improve reliability when the query result set
          is large. In addition to this limit, responses are also limited to 10 MB.
          By default, there is no maximum row count, and only the byte limit applies.'
      timeoutMs?:
        type: integer
        format: int32
        description: '[Optional] How long to wait for the query to complete, in milliseconds,
          before the request times out and returns. Note that this is only a timeout
          for the request, not the query. If the query takes longer to run than the
          timeout value, the call returns without any results and with the ''jobComplete''
          flag set to false. You can call GetQueryResults() to wait for the query
          to complete and read the results. The default value is 10000 milliseconds
          (10 seconds).'
      preserveNulls?:
        type: boolean
        description: '[Deprecated] This property is deprecated.'
      query?:
        type: string
        description: '[Required] A query string, following the BigQuery query syntax,
          of the query to execute. Example: "SELECT count(f1) FROM [myProjectId:myDatasetId.myTableId]".'
      defaultDataset?: DatasetReference
      useLegacySql?:
        type: boolean
        default: true
        description: '[Experimental] Specifies whether to use BigQuery''s legacy SQL
          dialect for this query. The default value is true. If set to false, the
          query will use BigQuery''s standard SQL: https://cloud.google.com/bigquery/sql-reference/
          When useLegacySql is set to false, the values of allowLargeResults and flattenResults
          are ignored; query will be run as if allowLargeResults is true and flattenResults
          is false.'
  QueryResponse:
    type: object
    properties:
      schema?: TableSchema
      kind?:
        type: string
        default: bigquery#queryResponse
        description: The resource type.
      cacheHit?:
        type: boolean
        description: Whether the query result was fetched from the query cache.
      jobComplete?:
        type: boolean
        description: Whether the query has completed or not. If rows or totalRows are present, this will always be true. If this is false, totalRows will not be available.
      numDmlAffectedRows?:
        type: integer
        format: int64
        description: '[Output-only, Experimental] The number of rows affected by a
          DML statement. Present only for DML statements INSERT, UPDATE or DELETE.'
      pageToken?:
        type: string
        description: A token used for paging results.
      totalRows?:
        type: integer
        format: int64
        description: The total number of rows in the complete query result set, which can be more than the number of rows in this single page of results.
      jobReference?: JobReference
      rows?:
        type: array
        description: An object with as many results as can be contained within the maximum permitted reply size. To get any additional rows, you can call GetQueryResults and specify the jobReference returned above.
        items: TableRow
      errors?:
        type: array
        description: '[Output-only] All errors and warnings encountered during the
          running of the job. Errors here do not necessarily mean that the job has
          completed or was unsuccessful.'
        items: ErrorProto
      totalBytesProcessed?:
        type: integer
        format: int64
        description: The total number of bytes processed for this query. If this query was a dry run, this is the number of bytes that would be processed if the query were run.
  Streamingbuffer:
    type: object
    properties:
      estimatedBytes?:
        type: integer
        format: int64
        description: '[Output-only] A lower-bound estimate of the number of bytes
          currently in the streaming buffer.'
      oldestEntryTime?:
        type: integer
        format: int64
        description: '[Output-only] Contains the timestamp of the oldest entry in
          the streaming buffer, in milliseconds since the epoch, if the streaming
          buffer is available.'
      estimatedRows?:
        type: integer
        format: int64
        description: '[Output-only] A lower-bound estimate of the number of rows currently
          in the streaming buffer.'
  Table:
    type: object
    properties:
      schema?: TableSchema
      timePartitioning?: TimePartitioning
      lastModifiedTime?:
        type: integer
        format: int64
        description: '[Output-only] The time when this table was last modified, in
          milliseconds since the epoch.'
      streamingBuffer?: Streamingbuffer
      creationTime?:
        type: integer
        format: int64
        description: '[Output-only] The time when this table was created, in milliseconds
          since the epoch.'
      numRows?:
        type: integer
        format: int64
        description: '[Output-only] The number of rows of data in this table, excluding
          any data in the streaming buffer.'
      kind?:
        type: string
        default: bigquery#table
        description: '[Output-only] The type of the resource.'
      description?:
        type: string
        description: '[Optional] A user-friendly description of this table.'
      type?:
        type: string
        description: '[Output-only] Describes the table type. The following values
          are supported: TABLE: A normal BigQuery table. VIEW: A virtual table defined
          by a SQL query. EXTERNAL: A table that references data stored in an external
          storage system, such as Google Cloud Storage. The default value is TABLE.'
      selfLink?:
        type: string
        description: '[Output-only] A URL that can be used to access this resource
          again.'
      numBytes?:
        type: integer
        format: int64
        description: '[Output-only] The size of this table in bytes, excluding any
          data in the streaming buffer.'
      externalDataConfiguration?: ExternalDataConfiguration
      view?: ViewDefinition
      numLongTermBytes?:
        type: integer
        format: int64
        description: '[Output-only] The number of bytes in the table that are considered
          "long-term storage".'
      tableReference?: TableReference
      expirationTime?:
        type: integer
        format: int64
        description: '[Optional] The time when this table expires, in milliseconds
          since the epoch. If not present, the table will persist indefinitely. Expired
          tables will be deleted and their storage reclaimed.'
      etag?:
        type: string
        description: '[Output-only] A hash of this resource.'
      location?:
        type: string
        description: '[Output-only] The geographic location where the table resides.
          This value is inherited from the dataset.'
      id?:
        type: string
        description: '[Output-only] An opaque ID uniquely identifying the table.'
      friendlyName?:
        type: string
        description: '[Optional] A descriptive name for this table.'
  TableCell:
    type: object
    properties:
      v?:
        type: any
  TableDataInsertAllRequest:
    type: object
    properties:
      skipInvalidRows?:
        type: boolean
        description: '[Optional] Insert all valid rows of a request, even if invalid
          rows exist. The default value is false, which causes the entire request
          to fail if any invalid rows exist.'
      kind?:
        type: string
        default: bigquery#tableDataInsertAllRequest
        description: The resource type of the response.
      templateSuffix?:
        type: string
        description: '[Experimental] If specified, treats the destination table as
          a base template, and inserts the rows into an instance table named "{destination}{templateSuffix}".
          BigQuery will manage creation of the instance table, using the schema of
          the base template table. See https://cloud.google.com/bigquery/streaming-data-into-bigquery#template-tables
          for considerations when working with templates tables.'
      ignoreUnknownValues?:
        type: boolean
        description: '[Optional] Accept rows that contain values that do not match
          the schema. The unknown values are ignored. Default is false, which treats
          unknown values as errors.'
      rows?:
        type: array
        description: The rows to insert.
        items:
          type: object
          properties:
            json?: JsonObject
            insertId?:
              type: string
              description: '[Optional] A unique ID for each row. BigQuery uses this
                property to detect duplicate insertion requests on a best-effort basis.'
  TableDataInsertAllResponse:
    type: object
    properties:
      insertErrors?:
        type: array
        description: An array of errors for rows that were not inserted.
        items:
          type: object
          properties:
            index?:
              type: integer
              format: int32
              description: The index of the row that error applies to.
            errors?:
              type: array
              description: Error information for the row indicated by the index property.
              items: ErrorProto
      kind?:
        type: string
        default: bigquery#tableDataInsertAllResponse
        description: The resource type of the response.
  TableDataList:
    type: object
    properties:
      kind?:
        type: string
        default: bigquery#tableDataList
        description: The resource type of the response.
      etag?:
        type: string
        description: A hash of this page of results.
      pageToken?:
        type: string
        description: A token used for paging results. Providing this token instead of the startIndex parameter can help you retrieve stable results when an underlying table is changing.
      totalRows?:
        type: integer
        format: int64
        description: The total number of rows in the complete table.
      rows?:
        type: array
        description: Rows of results.
        items: TableRow
  TableFieldSchema:
    type: object
    properties:
      mode?:
        type: string
        description: '[Optional] The field mode. Possible values include NULLABLE,
          REQUIRED and REPEATED. The default value is NULLABLE.'
      name?:
        type: string
        description: '[Required] The field name. The name must contain only letters
          (a-z, A-Z), numbers (0-9), or underscores (_), and must start with a letter
          or underscore. The maximum length is 128 characters.'
      description?:
        type: string
        description: '[Optional] The field description. The maximum length is 16K
          characters.'
      fields?:
        type: array
        description: '[Optional] Describes the nested schema fields if the type property
          is set to RECORD.'
        items: TableFieldSchema
      type?:
        type: string
        description: '[Required] The field data type. Possible values include STRING,
          BYTES, INTEGER, FLOAT, BOOLEAN, TIMESTAMP, DATE, TIME, DATETIME, or RECORD
          (where RECORD indicates that the field contains a nested schema).'
  TableList:
    type: object
    properties:
      tables?:
        type: array
        description: Tables in the requested dataset.
        items:
          type: object
          properties:
            tableReference?: TableReference
            kind?:
              type: string
              default: bigquery#table
              description: The resource type.
            id?:
              type: string
              description: An opaque ID of the table
            type?:
              type: string
              description: 'The type of table. Possible values are: TABLE, VIEW.'
            friendlyName?:
              type: string
              description: The user-friendly name for this table.
      totalItems?:
        type: integer
        format: int32
        description: The total number of tables in the dataset.
      kind?:
        type: string
        default: bigquery#tableList
        description: The type of list.
      nextPageToken?:
        type: string
        description: A token to request the next page of results.
      etag?:
        type: string
        description: A hash of this page of results.
  TableReference:
    type: object
    properties:
      datasetId?:
        type: string
        description: '[Required] The ID of the dataset containing this table.'
      tableId?:
        type: string
        description: '[Required] The ID of the table. The ID must contain only letters
          (a-z, A-Z), numbers (0-9), or underscores (_). The maximum length is 1,024
          characters.'
      projectId?:
        type: string
        description: '[Required] The ID of the project containing this table.'
  TableRow:
    type: object
    properties:
      f?:
        type: array
        description: Represents a single row in the result set, consisting of one or more fields.
        items: TableCell
  TableSchema:
    type: object
    properties:
      fields?:
        type: array
        description: Describes the fields in a table.
        items: TableFieldSchema
  TimePartitioning:
    type: object
    properties:
      expirationMs?:
        type: integer
        format: int64
        description: '[Optional] Number of milliseconds for which to keep the storage
          for a partition.'
      type?:
        type: string
        description: '[Required] The only type supported is DAY, which will generate
          one partition per day based on data loading time.'
  UserDefinedFunctionResource:
    type: object
    properties:
      resourceUri?:
        type: string
        description: '[Pick one] A code resource to load from a Google Cloud Storage
          URI (gs://bucket/path).'
      inlineCode?:
        type: string
        description: '[Pick one] An inline resource that contains code for a user-defined
          function (UDF). Providing a inline code resource is equivalent to providing
          a URI for a file containing the same code.'
  ViewDefinition:
    type: object
    properties:
      userDefinedFunctionResources?:
        type: array
        description: '[Experimental] Describes user-defined function resources used
          in the query.'
        items: UserDefinedFunctionResource
      query?:
        type: string
        description: '[Required] A query that BigQuery executes when the view is referenced.'
      useLegacySql?:
        type: boolean
        description: '[Experimental] Specifies whether to use BigQuery''s legacy SQL
          for this view. The default value is true. If set to false, the view will
          use BigQuery''s standard SQL: https://cloud.google.com/bigquery/sql-reference/
          Queries and views that reference this view must use the same flag value.'
/projects:
  /{projectId}:
    uriParameters:
      projectId:
        type: string
        description: Project ID of the table to update
    /datasets:
      /{datasetId}:
        uriParameters:
          datasetId:
            type: string
            description: Dataset ID of the table to update
        /tables:
          /{tableId}:
            uriParameters:
              tableId:
                type: string
                description: Table ID of the table to update
            /data:
              get:
                securedBy:
                  oath2:
                    scopes:
                    - https://www.googleapis.com/auth/bigquery
                    - https://www.googleapis.com/auth/cloud-platform
                    - https://www.googleapis.com/auth/cloud-platform.read-only
                description: Retrieves table data from a specified set of rows. Requires the READER dataset role.
                displayName: List Tabledata
                is:
                - hasParameters
                queryParameters:
                  startIndex?:
                    type: integer
                    format: int64
                    description: Zero-based index of the starting row to read
                  maxResults?:
                    type: integer
                    format: int32
                    description: Maximum number of results to return
                  pageToken?:
                    type: string
                    description: Page token, returned by a previous call, identifying the result set
                responses:
                  200:
                    body:
                      application/json: TableDataList
            /insertAll:
              post:
                securedBy:
                  oath2:
                    scopes:
                    - https://www.googleapis.com/auth/bigquery
                    - https://www.googleapis.com/auth/bigquery.insertdata
                    - https://www.googleapis.com/auth/cloud-platform
                description: Streams data into BigQuery one record at a time without needing to run a load job. Requires the WRITER dataset role.
                displayName: InsertAll Tabledata
                is:
                - hasParameters
                body:
                  application/json: TableDataInsertAllRequest
                responses:
                  200:
                    body:
                      application/json: TableDataInsertAllResponse
            patch:
              securedBy:
                oath2:
                  scopes:
                  - https://www.googleapis.com/auth/bigquery
                  - https://www.googleapis.com/auth/cloud-platform
              description: Updates information in an existing table. The update method replaces the entire table resource, whereas the patch method only replaces fields that are provided in the submitted table resource. This method supports patch semantics.
              displayName: Patch Tables
              is:
              - hasParameters
              body:
                application/json: Table
              responses:
                200:
                  body:
                    application/json: Table
            get:
              securedBy:
                oath2:
                  scopes:
                  - https://www.googleapis.com/auth/bigquery
                  - https://www.googleapis.com/auth/cloud-platform
                  - https://www.googleapis.com/auth/cloud-platform.read-only
              description: Gets the specified table resource by table ID. This method does not return the data in the table, it only returns the table resource, which describes the structure of this table.
              displayName: Get Tables
              is:
              - hasParameters
              responses:
                200:
                  body:
                    application/json: Table
            put:
              securedBy:
                oath2:
                  scopes:
                  - https://www.googleapis.com/auth/bigquery
                  - https://www.googleapis.com/auth/cloud-platform
              description: Updates information in an existing table. The update method replaces the entire table resource, whereas the patch method only replaces fields that are provided in the submitted table resource.
              displayName: Update Tables
              is:
              - hasParameters
              body:
                application/json: Table
              responses:
                200:
                  body:
                    application/json: Table
            delete:
              securedBy:
                oath2:
                  scopes:
                  - https://www.googleapis.com/auth/bigquery
                  - https://www.googleapis.com/auth/cloud-platform
              description: Deletes the table specified by tableId from the dataset. If the table contains data, all the data will be deleted.
              displayName: Delete Tables
              is:
              - hasParameters
          post:
            securedBy:
              oath2:
                scopes:
                - https://www.googleapis.com/auth/bigquery
                - https://www.googleapis.com/auth/cloud-platform
            description: Creates a new, empty table in the dataset.
            displayName: Insert Tables
            is:
            - hasParameters
            body:
              application/json: Table
            responses:
              200:
                body:
                  application/json: Table
          get:
            securedBy:
              oath2:
                scopes:
                - https://www.googleapis.com/auth/bigquery
                - https://www.googleapis.com/auth/cloud-platform
                - https://www.googleapis.com/auth/cloud-platform.read-only
            description: Lists all tables in the specified dataset. Requires the READER dataset role.
            displayName: List Tables
            is:
            - hasParameters
            queryParameters:
              maxResults?:
                type: integer
                format: int32
                description: Maximum number of results to return
              pageToken?:
                type: string
                description: Page token, returned by a previous call, to request the next page of results
            responses:
              200:
                body:
                  application/json: TableList
        patch:
          securedBy:
            oath2:
              scopes:
              - https://www.googleapis.com/auth/bigquery
              - https://www.googleapis.com/auth/cloud-platform
          description: Updates information in an existing dataset. The update method replaces the entire dataset resource, whereas the patch method only replaces fields that are provided in the submitted dataset resource. This method supports patch semantics.
          displayName: Patch Datasets
          is:
          - hasParameters
          body:
            application/json: Dataset
          responses:
            200:
              body:
                application/json: Dataset
        get:
          securedBy:
            oath2:
              scopes:
              - https://www.googleapis.com/auth/bigquery
              - https://www.googleapis.com/auth/cloud-platform
              - https://www.googleapis.com/auth/cloud-platform.read-only
          description: Returns the dataset specified by datasetID.
          displayName: Get Datasets
          is:
          - hasParameters
          responses:
            200:
              body:
                application/json: Dataset
        put:
          securedBy:
            oath2:
              scopes:
              - https://www.googleapis.com/auth/bigquery
              - https://www.googleapis.com/auth/cloud-platform
          description: Updates information in an existing dataset. The update method replaces the entire dataset resource, whereas the patch method only replaces fields that are provided in the submitted dataset resource.
          displayName: Update Datasets
          is:
          - hasParameters
          body:
            application/json: Dataset
          responses:
            200:
              body:
                application/json: Dataset
        delete:
          securedBy:
            oath2:
              scopes:
              - https://www.googleapis.com/auth/bigquery
              - https://www.googleapis.com/auth/cloud-platform
          description: Deletes the dataset specified by the datasetId value. Before you can delete a dataset, you must delete all its tables, either manually or by specifying deleteContents. Immediately after deletion, you can create another dataset with the same name.
          displayName: Delete Datasets
          is:
          - hasParameters
          queryParameters:
            deleteContents?:
              type: boolean
              description: If True, delete all the tables in the dataset. If False and the dataset contains tables, the request will fail. Default is False
      post:
        securedBy:
          oath2:
            scopes:
            - https://www.googleapis.com/auth/bigquery
            - https://www.googleapis.com/auth/cloud-platform
        description: Creates a new empty dataset.
        displayName: Insert Datasets
        is:
        - hasParameters
        body:
          application/json: Dataset
        responses:
          200:
            body:
              application/json: Dataset
      get:
        securedBy:
          oath2:
            scopes:
            - https://www.googleapis.com/auth/bigquery
            - https://www.googleapis.com/auth/cloud-platform
            - https://www.googleapis.com/auth/cloud-platform.read-only
        description: Lists all datasets in the specified project to which you have been granted the READER dataset role.
        displayName: List Datasets
        is:
        - hasParameters
        queryParameters:
          all?:
            type: boolean
            description: Whether to list all datasets, including hidden ones
          filter?:
            type: string
            description: 'An expression for filtering the results of the request by
              label. The syntax is "labels.<name>[:<value>]". Multiple filters can
              be ANDed together by connecting with a space. Example: "labels.department:receiving
              labels.active". See Filtering datasets using labels for details.'
          maxResults?:
            type: integer
            format: int32
            description: The maximum number of results to return
          pageToken?:
            type: string
            description: Page token, returned by a previous call, to request the next page of results
        responses:
          200:
            body:
              application/json: DatasetList
    /jobs:
      /{jobId}:
        uriParameters:
          jobId:
            type: string
            description: '[Required] Job ID of the job to cancel'
        /cancel:
          post:
            securedBy:
              oath2:
                scopes:
                - https://www.googleapis.com/auth/bigquery
                - https://www.googleapis.com/auth/cloud-platform
            description: Requests that a job be cancelled. This call will return immediately, and the client will need to poll for the job status to see if the cancel completed successfully. Cancelled jobs may still incur costs.
            displayName: Cancel Jobs
            is:
            - hasParameters
            responses:
              200:
                body:
                  application/json: JobCancelResponse
        get:
          securedBy:
            oath2:
              scopes:
              - https://www.googleapis.com/auth/bigquery
              - https://www.googleapis.com/auth/cloud-platform
              - https://www.googleapis.com/auth/cloud-platform.read-only
          description: Returns information about a specific job. Job information is available for a six month period after creation. Requires that you're the person who ran the job, or have the Is Owner project role.
          displayName: Get Jobs
          is:
          - hasParameters
          responses:
            200:
              body:
                application/json: Job
      post:
        securedBy:
          oath2:
            scopes:
            - https://www.googleapis.com/auth/bigquery
            - https://www.googleapis.com/auth/cloud-platform
            - https://www.googleapis.com/auth/devstorage.full_control
            - https://www.googleapis.com/auth/devstorage.read_only
            - https://www.googleapis.com/auth/devstorage.read_write
        description: Starts a new asynchronous job. Requires the Can View project role.
        displayName: Insert Jobs
        is:
        - hasParameters
        body:
          application/json: Job
        responses:
          200:
            body:
              application/json: Job
      get:
        securedBy:
          oath2:
            scopes:
            - https://www.googleapis.com/auth/bigquery
            - https://www.googleapis.com/auth/cloud-platform
            - https://www.googleapis.com/auth/cloud-platform.read-only
        description: Lists all jobs that you started in the specified project. Job information is available for a six month period after creation. The job list is sorted in reverse chronological order, by job creation time. Requires the Can View project role, or the Is Owner project role if you set the allUsers property.
        displayName: List Jobs
        is:
        - hasParameters
        queryParameters:
          stateFilter?:
            type: string
            description: Filter for job state
            enum:
            - done
            - pending
            - running
          allUsers?:
            type: boolean
            description: Whether to display jobs owned by all users in the project. Default false
          maxResults?:
            type: integer
            format: int32
            description: Maximum number of results to return
          pageToken?:
            type: string
            description: Page token, returned by a previous call, to request the next page of results
          projection?:
            type: string
            description: Restrict information returned to a set of selected fields
            enum:
            - full
            - minimal
        responses:
          200:
            body:
              application/json: JobList
    /queries:
      /{jobId}:
        uriParameters:
          jobId:
            type: string
            description: '[Required] Job ID of the query job'
        get:
          securedBy:
            oath2:
              scopes:
              - https://www.googleapis.com/auth/bigquery
              - https://www.googleapis.com/auth/cloud-platform
              - https://www.googleapis.com/auth/cloud-platform.read-only
          description: Retrieves the results of a query job.
          displayName: GetQueryResults Jobs
          is:
          - hasParameters
          queryParameters:
            startIndex?:
              type: integer
              format: int64
              description: Zero-based index of the starting row
            maxResults?:
              type: integer
              format: int32
              description: Maximum number of results to read
            timeoutMs?:
              type: integer
              format: int32
              description: How long to wait for the query to complete, in milliseconds, before returning. Default is 10 seconds. If the timeout passes before the job completes, the 'jobComplete' field in the response will be false
            pageToken?:
              type: string
              description: Page token, returned by a previous call, to request the next page of results
          responses:
            200:
              body:
                application/json: GetQueryResultsResponse
      post:
        securedBy:
          oath2:
            scopes:
            - https://www.googleapis.com/auth/bigquery
            - https://www.googleapis.com/auth/cloud-platform
            - https://www.googleapis.com/auth/cloud-platform.read-only
        description: Runs a BigQuery SQL query synchronously and returns query results if the query completes within a specified timeout.
        displayName: Query Jobs
        is:
        - hasParameters
        body:
          application/json: QueryRequest
        responses:
          200:
            body:
              application/json: QueryResponse
  get:
    securedBy:
      oath2:
        scopes:
        - https://www.googleapis.com/auth/bigquery
        - https://www.googleapis.com/auth/cloud-platform
        - https://www.googleapis.com/auth/cloud-platform.read-only
    description: Lists all projects to which you have been granted any project role.
    displayName: List Projects
    is:
    - hasParameters
    queryParameters:
      maxResults?:
        type: integer
        format: int32
        description: Maximum number of results to return
      pageToken?:
        type: string
        description: Page token, returned by a previous call, to request the next page of results
    responses:
      200:
        body:
          application/json: ProjectList
